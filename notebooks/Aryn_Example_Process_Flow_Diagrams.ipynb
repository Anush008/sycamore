{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmWYx6Ps4zGI"
      },
      "source": [
        "This notebook walks through an example of how to use the Aryn Partitioning Service with OpenAI's gpt-40-mini model to transform process flow diagrams (PFDs) into a DAG that is loaded into neo4j.\n",
        "\n",
        "We first use the Aryn SDK to pull out an image of the PFD from a page. We then send that diagram to OpenAI's gpt model and ask it to transform the contents of that flow into a DAG expressed as nodes and edges in a JSON which are then loaded into neo4j.\n",
        "\n",
        "You will need an Aryn API key, an Open AI API key, and a neo4j AuraDB instance to run this notebook. You can obtain an Aryn API key [here](https://www.aryn.ai/get-started ), an OpenAI API key [here](https://platform.openai.com/api-keys), and a neo4j AuraDB instance [here](https://neo4j.com/product/auradb/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNH8HPu7409O"
      },
      "outputs": [],
      "source": [
        "#Install Aryn SDK\n",
        "!pip install aryn-sdk\n",
        "\n",
        "#Install Poppler utils so the PDF can be displayed\n",
        "!apt-get install poppler-utils\n",
        "\n",
        "#Install OpenAI SDK\n",
        "!pip install openai\n",
        "\n",
        "#Install pydantic\n",
        "!pip install pydantic\n",
        "\n",
        "#Install neo4j\n",
        "!pip install neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Knwd0aFB43U1"
      },
      "outputs": [],
      "source": [
        "# Import necessary functions\n",
        "import aryn_sdk\n",
        "from aryn_sdk.partition import partition_file, draw_with_boxes, convert_image_element, table_elem_to_dataframe\n",
        "import json\n",
        "import pdf2image\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel\n",
        "from openai.lib._parsing import type_to_response_format_param as pydantic_to_response_format\n",
        "from neo4j import GraphDatabase\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovTTZl0D46PD"
      },
      "outputs": [],
      "source": [
        "# Set your secrets in the colab notebook. Navigate to the left pane\n",
        "# and choose the key option to set your keys. Make sure to enable Notebook access\n",
        "\n",
        "# Visit https://www.aryn.ai/get-started to get a key.\n",
        "aryn_api_key = userdata.get('aryn_api_key')\n",
        "\n",
        "# Visit https://platform.openai.com/api-keys to get a key.\n",
        "openai_api_key = userdata.get('openai_api_key')\n",
        "\n",
        "# Visit https://neo4j.com/product/auradb/ to get neo4j URI, Username, and Password\n",
        "neo4j_uri = userdata.get('NEO4J_URI')\n",
        "neo4j_username = userdata.get('NEO4J_USERNAME')\n",
        "neo4j_password = userdata.get('NEO4J_PASSWORD')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg3QKhZW47fl"
      },
      "outputs": [],
      "source": [
        "# get files from Aryn's public S3 bucket.\n",
        "![ -f PFD2.pdf ] || wget https://aryn-public.s3.amazonaws.com/partitioner-blog-data/PFD2.pdf\n",
        "![ -f PFD_2017.pdf ] || wget https://aryn-public.s3.amazonaws.com/partitioner-blog-data/PFD_2017.pdf\n",
        "![ -f PFD_2018.pdf ] || wget https://aryn-public.s3.amazonaws.com/partitioner-blog-data/PFD_2018.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtXJ04cG48sF"
      },
      "outputs": [],
      "source": [
        "# open the file\n",
        "file_name = 'PFD2.pdf'\n",
        "\n",
        "# show the pdf\n",
        "pdf2image.convert_from_path(file_name)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzVqaoHK4_Cy"
      },
      "outputs": [],
      "source": [
        "# Open the file.\n",
        "file = open(file_name, 'rb')\n",
        "\n",
        "## Make a call to the partitioning service to break down the file into its constituent\n",
        "## components: images, tables, and captions. The documents elements are returned in a Python dict.\n",
        "document_dict = partition_file(file, aryn_api_key, extract_images=True, extract_table_structure=True, use_ocr=True, threshold=0.20)\n",
        "\n",
        "# show the pdf with bounding boxes of the elements superimposed.\n",
        "draw_with_boxes(file_name, document_dict)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F001V3lH5A8o"
      },
      "outputs": [],
      "source": [
        "## Walk over the table elements in the returned document dict and show the first one\n",
        "tables = [e for e in document_dict['elements'] if e['type'] == 'table']\n",
        "\n",
        "## Convert the table to a pandas dataframe and display it.\n",
        "table_df = table_elem_to_dataframe(tables[0])\n",
        "display(table_df)\n",
        "print(\"\\n\")\n",
        "\n",
        "## Walk over the image elements in the returned document dict and show the first one\n",
        "images = [e for e in document_dict['elements'] if e['type'] == 'Image']\n",
        "images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "Jg17yuf2OJu8",
        "outputId": "be17e553-4e35-42bb-ba57-c6b37b6954dc"
      },
      "outputs": [],
      "source": [
        "## Let's convert image to PIL to see it more closely.\n",
        "pil_img = convert_image_element(images[0], format='PIL')\n",
        "display(pil_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvEvd9QKgozH"
      },
      "outputs": [],
      "source": [
        "# Setup Pydantic models for a labeled DAG (directed acyclic graph) to form a response_format for gpt-4o\n",
        "class node(BaseModel):\n",
        "    label: str\n",
        "    description: str\n",
        "\n",
        "class edge(BaseModel):\n",
        "    source: str\n",
        "    target: str\n",
        "    description: str\n",
        "\n",
        "class diagram_DAG(BaseModel):\n",
        "    nodes: list[node]\n",
        "    edges: list[edge]\n",
        "\n",
        "response_format = pydantic_to_response_format(diagram_DAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4e8XtTFfTGft",
        "outputId": "cce9fedc-0210-47a4-c1d7-6ed22179e03d"
      },
      "outputs": [],
      "source": [
        "# convert image to base64 encoded JPEG for OpenAI to process it.\n",
        "jpeg_img = convert_image_element(images[0], format='JPEG', b64encode=True)\n",
        "\n",
        "# Execute a completion request to gpt-4o and print the response.\n",
        "openai_client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "response = openai_client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\"type\": \"text\",\n",
        "         \"text\": \"\"\"Transform the following PFD (process flow) diagram into a DAG and return it in JSON.\n",
        "                    Ensure each node has a unique label. Ignore the labeled circles.\n",
        "                 \"\"\"},\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\"url\": f\"data:image/jpeg;base64,{jpeg_img}\", \"detail\": \"high\"},\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        "  # Ask openAI to respond back with\n",
        "  response_format = response_format,\n",
        "  max_tokens=1000,\n",
        ")\n",
        "\n",
        "# The response from gpt-4o will be a JSON string\n",
        "DAG_json = response.choices[0].message.content\n",
        "# print(\"Returned JSON:\")\n",
        "# print(DAG_json)\n",
        "# print(\"\\n\")\n",
        "\n",
        "# Load the JSON response from gpt-4o into a dict and print it\n",
        "DAG_dict = json.loads(DAG_json)\n",
        "print(\"Python DAG:\")\n",
        "print(\"Nodes:\")\n",
        "for n in DAG_dict['nodes']:\n",
        "  print(f\"  \\\"{n['label']}\\\": \\\"{n['description']}\\\"\")\n",
        "print(\"Edges:\")\n",
        "for e in DAG_dict['edges']:\n",
        "  print(f\"  \\\"{e['source']}\\\" -> \\\"{e['target']}\\\": \\\"{e['description']}\\\"\")\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmsM2ZgwswaX"
      },
      "outputs": [],
      "source": [
        "# This function combines all of the above mentioned steps\n",
        "\n",
        "def convert_pfd_to_dag(pfd_fn: str, openai_client: OpenAI) -> dict:\n",
        "\n",
        "  # show the first page of the PDF\n",
        "  # display(pdf2image.convert_from_path(pfd_fn)[0])\n",
        "\n",
        "  # Open the file.\n",
        "  pfd_file = open(pfd_fn, 'rb')\n",
        "\n",
        "  ## Make a call to the partitioning service to break down the filex into their constituent\n",
        "  ## components: images, tables, and captions.\n",
        "  pfd_dict = partition_file(pfd_file, aryn_api_key, extract_images=True, extract_table_structure=True, use_ocr=True, threshold=0.20)\n",
        "\n",
        "  ## Walk over the image elements in the returned document dict and show the first one\n",
        "  pfd_images = [e for e in pfd_dict['elements'] if e['type'] == 'Image']\n",
        "\n",
        "  print(\"Converting this PFD diagram: \")\n",
        "  ## Let's convert image to PIL to see it more closely.\n",
        "  pfd_pil_img = convert_image_element(pfd_images[0], format='PIL')\n",
        "  display(pfd_pil_img)\n",
        "\n",
        "  # convert image to base64 encoded JPEG for gpt-4o-mini to process it.\n",
        "  pfd_jpeg = convert_image_element(pfd_images[0], format='JPEG', b64encode=True)\n",
        "\n",
        "  print(\"Calling gpt-4o: \")\n",
        "  response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "          {\"type\": \"text\",\n",
        "           \"text\": \"\"\"Transform the following PFD (process flow) diagram into a DAG and return it in JSON.\n",
        "                      Ensure each node has a unique label. \"\"\"},\n",
        "          {\"type\": \"image_url\",\n",
        "           \"image_url\": {\"url\": f\"data:image/jpeg;base64,{pfd_jpeg}\", \"detail\": \"high\"},},\n",
        "        ],\n",
        "      }\n",
        "    ],\n",
        "\n",
        "    # Ask openAI to respond back with\n",
        "    response_format = response_format,\n",
        "    max_tokens=5000,\n",
        "  )\n",
        "\n",
        "  # The response from gpt-4o will be a JSON string\n",
        "  pfd_json = response.choices[0].message.content\n",
        "  # print(\"Returned JSON:\")\n",
        "  # print(pfd_json)\n",
        "  # print(\"\\n\")\n",
        "\n",
        "  # Load the JSON response from gpt-4o into a dict and print it\n",
        "  pfd_DAG = json.loads(pfd_json)\n",
        "  print(\"Python DAG:\")\n",
        "  print(\"Nodes:\")\n",
        "  for n in pfd_DAG['nodes']:\n",
        "    print(f\"  \\\"{n['label']}\\\": \\\"{n['description']}\\\"\")\n",
        "  print(\"Edges:\")\n",
        "  for e in pfd_DAG['edges']:\n",
        "    print(f\"  \\\"{e['source']}\\\" -> \\\"{e['target']}\\\": \\\"{e['description']}\\\"\")\n",
        "  print(\"\\n\")\n",
        "\n",
        "  return pfd_DAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE1MXEbQwX7m"
      },
      "outputs": [],
      "source": [
        "pfd_2017 = convert_pfd_to_dag('PFD_2017.pdf', openai_client)\n",
        "pfd_2018  = convert_pfd_to_dag('PFD_2018.pdf', openai_client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "driver = GraphDatabase.driver(uri=neo4j_uri, auth=(neo4j_username, neo4j_password))\n",
        "\n",
        "def convert_graph_to_neo4j(pfd):\n",
        "    nodes_prompts = []\n",
        "    for i, node in enumerate(pfd[\"nodes\"]):\n",
        "        query = f\"MERGE (n:Node {{label: '{node['label']}', description: '{node['description']}'}})\"\n",
        "        nodes_prompts.append(query)\n",
        "\n",
        "    edges_prompts = []\n",
        "    for i, edge in enumerate(pfd[\"edges\"]):\n",
        "        source_label = edge[\"source\"]\n",
        "        target_label = edge[\"target\"]\n",
        "        description = edge[\"description\"]\n",
        "        \n",
        "        query = f\"\"\"\n",
        "        MATCH (n:Node {{label: '{source_label}'}})\n",
        "        MATCH (k:Node {{label: '{target_label}'}})\n",
        "        WITH n, k\n",
        "        WHERE n IS NOT NULL AND k IS NOT NULL\n",
        "        MERGE (n)-[:Edge {{description: '{description}'}}]->(k)\n",
        "        \"\"\"\n",
        "        edges_prompts.append(query)\n",
        "\n",
        "    return nodes_prompts, edges_prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Load PFD_2017 into neo4j\n",
        "nodes, edges = convert_graph_to_neo4j(pfd_2017)\n",
        "with driver.session() as tx:\n",
        "  for node_prompt in nodes:\n",
        "    tx.run(node_prompt)\n",
        "  for edge_prompt in edges:\n",
        "    tx.run(edge_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Delete Neo4j\n",
        "with driver.session() as tx:\n",
        "    tx.run(\"\"\"\n",
        "    MATCH (n) \n",
        "    DETACH DELETE n;\"\"\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Load PFD_2018 into neo4j\n",
        "nodes, edges = convert_graph_to_neo4j(pfd_2018)\n",
        "with driver.session() as tx:\n",
        "  for node_prompt in nodes:\n",
        "    tx.run(node_prompt)\n",
        "  for edge_prompt in edges:\n",
        "    tx.run(edge_prompt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
